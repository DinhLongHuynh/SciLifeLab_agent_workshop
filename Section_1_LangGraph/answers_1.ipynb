{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41992144",
   "metadata": {},
   "source": [
    "<img src=\"images/scilife_logo.png\" width=\"400\">\n",
    "<img src=\"images/essence_logo.png\" width=\"300\">\n",
    "\n",
    "# SciLifeLab Workshop - Hands-on Section: LangGraph \"Hello World\"\n",
    "\n",
    "\n",
    "\n",
    "Welcome to this hands‑on lab session on building AI agents with **LangGraph**! LangGraph is a low‑level orchestration framework for constructing stateful AI workflows using graphs, where nodes represent units of work and edges define how those units are connected. LangGraph provides several key benefits for agentic AI applications, including durable execution, support for human‑in‑the‑loop workflows, comprehensive memory (both short‑ and long‑term), built‑in debugging, and production‑ready deployment features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a60e0",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "By the end of this workshop you will:\n",
    "- Understand core concepts of LangGraph (tools, nodes, edges, state, and memory).\n",
    "- Create and integrate your own tools for an AI agent.\n",
    "- Build a ReAct‑style agent from scratch using an LLM and custom tools.\n",
    "- Implement agent memory to maintain conversational context.\n",
    "- Compare custom agents with prebuilt LangGraph agents.\n",
    "- Explore extension tasks such as error handling, streaming, and domain‑specific tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841aa80a",
   "metadata": {},
   "source": [
    "## Workshop Timeline (60 minutes)\n",
    "- **Part 1 (10 min)**: Setup & imports\n",
    "- **Part 2 (20 min)**: Understanding and creating tools\n",
    "- **Part 3 (10 min)**: Defining the state\n",
    "- **Part 4 (15 min)**: Building the agent graph\n",
    "- **Part 5 (5 min)**: Testing the agent\n",
    "- **Part 6 (10 min)**: Adding short‑term memory\n",
    "- **Part 7 (10 min)**: Exploring prebuilt agents\n",
    "- **Part 8 (optional)**: Extension exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba369",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 – Setup\n",
    "\n",
    "In this first step, we'll import the necessary dependencies and load any environment variables. Make sure your API keys (e.g. OpenAI) are stored in a `.env` file in the same directory.\n",
    "\n",
    "**Note: This part will be modified later if we used local model rather than OpenAI or Claude**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a6198",
   "metadata": {},
   "source": [
    "### Exercise 1.1 – Import dependencies (participant cell)\n",
    "\n",
    "Import the standard libraries and load environment variables:\n",
    "\n",
    "- Import json\n",
    "- Use `load_dotenv()` from the `dotenv` package to load variables from your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622c7f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import any packages you need here\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8cdae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 – Understanding and Creating Tools\n",
    "\n",
    "In LangGraph, **tools** are Python functions that extend your agent's capabilities beyond text generation. They can call external APIs or perform computations, and are annotated with the `@tool` decorator from LangChain. A tool takes typed inputs and returns a string; the LLM can decide when to call a tool as part of the conversation.\n",
    "\n",
    "When design tools for agent, there are 3 important considerations: \n",
    "- **Input - Output**: It is similar to when design python function, but the input now is handle by generated content from LLM. Output should be parsed to feed meaningful context for agent context \n",
    "\n",
    "- **Description**: the `@tool` decorator require docstrings from python function and will use it as tools description. These description will feed the LLM system prompts, make it to understand when to call which tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370dfa1",
   "metadata": {},
   "source": [
    "### Tool Creation API Reference\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def your_function_name(parameter: type) -> str:\n",
    "    \"\"\"Clear description of what this tool does.\n",
    "\n",
    "    Args:\n",
    "        parameter: Description of the parameter\n",
    "\n",
    "    Returns:\n",
    "        Information to pass back to the agent.\n",
    "    \"\"\"\n",
    "    # implementation here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fac64e",
   "metadata": {},
   "source": [
    "### About the task\n",
    "\n",
    "In this exercise, we will establish 3 tools that are useful for drug discovery domain.\n",
    "\n",
    "**1. Calculator:** a tool to execute mathematical expression\n",
    "\n",
    "**2. LitSearch:** a tool to perform semantic search on all publication available on PubMed\n",
    "\n",
    "**3. GetDrugInfo:** a tool to retrieve drugs information given drug name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdab0e4",
   "metadata": {},
   "source": [
    "### Exercise 2.1 – Create a Calculator Tool\n",
    "\n",
    "Write a tool that evaluates simple arithmetic expressions (e.g. `'2 + 3 * 4'`). Use Python's built‑in `eval` to perform the calculation, and wrap your function with the `@tool` decorator. Your tool should accept a string input called `expression` and return a string result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe36555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a simple arithmetic expression (e.g. '2 + 3 * 4').\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except Exception as exc:\n",
    "        return f\"Error evaluating expression: {exc}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e830fbe",
   "metadata": {},
   "source": [
    "### Exercise 2.2 – Create a Literature Search Tool\n",
    "\n",
    "Use the **LitSense** API to perform semantic search of PubMed articles. Your tool should accept a `query` string and an optional `limit` integer. Below is the API reference of LitSense Wrapper. Have a look at it to have implementation idea. \n",
    "\n",
    "### **LitSense API Reference**\n",
    "\n",
    "```python\n",
    "from litsense_wrapper import LitSense_API\n",
    "\n",
    "query = 'COVID-19 biological targers'\n",
    "engine = LitSense_API()\n",
    "results = engine.retrieve(query, limit=5) # return a list of LitSense object with attributes, such as text, pmid, etc.\n",
    "```\n",
    "\n",
    "### **References**\n",
    "LitSense: https://academic.oup.com/nar/article/53/W1/W361/8133630\n",
    "\n",
    "Github: https://github.com/DinhLongHuynh/LitSense_Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61a2613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from litsense_wrapper import LitSense_API\n",
    "\n",
    "@tool\n",
    "def lit_search(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Retrieve information from PubMed using a semantic search via the LitSense API.\\n\\n\n",
    "    Args:\n",
    "        query: The research question or topic to search for in PubMed literature.\n",
    "        limit: Maximum number of results to return (default is 5).\n",
    "    Returns:\n",
    "        A formatted string containing semantically relevant passages from PubMed articles, including PMID and content only.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        engine = LitSense_API()\n",
    "        results = engine.retrieve(query, limit=limit)\n",
    "        if not results:\n",
    "            return f\"No relevant literature found for '{query}'. Please try a different or broader search query.\"\n",
    "        result_str = \"\"\n",
    "        for i, result in enumerate(results):\n",
    "            result_str += (\n",
    "                f\"\\n--- Passage #{i+1} ---\\n\"\n",
    "                f\"PMID: {result.pmid}\\n\"\n",
    "                f\"Content: {result.text}\\n\"\n",
    "            )\n",
    "        return result_str\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving literature for '{query}': {str(e)}. Please try a different search query.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bfff2a",
   "metadata": {},
   "source": [
    "### Exercise 2.3 – Create a Drug Information Tool\n",
    "\n",
    "Build a tool that queries the **ChEMBL** database for comprehensive drug information. Use the `chembl_webresource_client` to search for molecules by name or synonym. If you find multiple candidates, select the first one. Return a formatted string containing the molecule's name, mechanism of action, and therapeutic indications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bcac328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chembl_webresource_client.new_client import new_client\n",
    "\n",
    "@tool\n",
    "def get_drug_info(drug_name: str) -> str:\n",
    "    \"\"\"Return comprehensive drug information using the ChEMBL database (supports synonyms).\"\"\"\n",
    "    try:\n",
    "        # Search for the molecule using synonyms/trade names\n",
    "        search_results = new_client.molecule.search(drug_name)\n",
    "        search_list = list(search_results)\n",
    "        if not search_list:\n",
    "            return f\"No information found for '{drug_name}'\"\n",
    "\n",
    "        candidate = search_list[0]\n",
    "        chembl_id = candidate['molecule_chembl_id']\n",
    "        details = new_client.molecule.get(chembl_id)\n",
    "\n",
    "        # Build base result\n",
    "        pref_name = details.get('pref_name') or candidate.get('pref_name') or drug_name\n",
    "        result = f\"**{pref_name}** (ChEMBL ID: {chembl_id})\\n\"\n",
    "        result += f\"Type: {details.get('molecule_type', 'Not specified')}\\n\"\n",
    "\n",
    "        # Include molecular formula if available\n",
    "        if details.get('molecule_properties', {}).get('molecular_formula'):\n",
    "            result += f\"Molecular Formula: {details['molecule_properties']['molecular_formula']}\\n\"\n",
    "\n",
    "        # Include synonyms/trade names if available\n",
    "        synonyms = details.get('molecule_synonyms', []) or []\n",
    "        if synonyms:\n",
    "            result += \"\\n**Synonyms/Trade names:**\\n\"\n",
    "            unique_synonyms = set()\n",
    "            for syn in synonyms[:15]:\n",
    "                name = syn.get('molecule_synonym') or syn.get('synonyms')\n",
    "                if name and name.lower() != pref_name.lower():\n",
    "                    unique_synonyms.add(name)\n",
    "            for name in sorted(unique_synonyms):\n",
    "                result += f\"- {name}\\n\"\n",
    "\n",
    "        # Mechanism of action\n",
    "        try:\n",
    "            mechanisms = new_client.mechanism.filter(\n",
    "                molecule_chembl_id=chembl_id\n",
    "            ).only(['mechanism_of_action', 'target_chembl_id'])\n",
    "            mechanism_list = list(mechanisms)\n",
    "            if mechanism_list:\n",
    "                result += \"\\n**Mechanism of Action:**\\n\"\n",
    "                unique_mechanisms = set()\n",
    "                for mech in mechanism_list[:5]:\n",
    "                    moa = mech.get('mechanism_of_action')\n",
    "                    if moa:\n",
    "                        unique_mechanisms.add(moa)\n",
    "                for moa in sorted(unique_mechanisms):\n",
    "                    result += f\"- {moa}\\n\"\n",
    "        except Exception as e:\n",
    "            result += f\"\\nMechanism of action data not available (Error: {str(e)[:50]}...)\\n\"\n",
    "\n",
    "        # Indications\n",
    "        try:\n",
    "            indications = new_client.drug_indication.filter(\n",
    "                molecule_chembl_id=chembl_id\n",
    "            ).only(['efo_term', 'mesh_heading', 'max_phase_for_ind'])\n",
    "            indication_list = list(indications)\n",
    "            if indication_list:\n",
    "                result += \"\\n**Indications:**\\n\"\n",
    "                unique_indications = set()\n",
    "                for ind in indication_list[:10]:\n",
    "                    indication_name = ind.get('efo_term') or ind.get('mesh_heading')\n",
    "                    max_phase = ind.get('max_phase_for_ind')\n",
    "                    if indication_name:\n",
    "                        phase_info = f\" (Phase {max_phase})\" if max_phase else \"\"\n",
    "                        unique_indications.add(f\"{indication_name}{phase_info}\")\n",
    "                for indication in sorted(unique_indications):\n",
    "                    result += f\"- {indication}\\n\"\n",
    "            else:\n",
    "                result += \"\\nNo indication data available.\\n\"\n",
    "        except Exception as e:\n",
    "            result += f\"\\nIndication data not available (Error: {str(e)[:50]}...)\\n\"\n",
    "\n",
    "        # Bioactivity summary\n",
    "        try:\n",
    "            activities = new_client.activity.filter(\n",
    "                molecule_chembl_id=chembl_id\n",
    "            ).only(['standard_type', 'standard_value', 'standard_units'])\n",
    "            activity_list = list(activities)\n",
    "            if activity_list:\n",
    "                result += f\"\\n**Bioactivity Data Available:** {len(activity_list)} records\\n\"\n",
    "                activity_types = {}\n",
    "                for act in activity_list[:100]:\n",
    "                    act_type = act.get('standard_type')\n",
    "                    if act_type:\n",
    "                        activity_types[act_type] = activity_types.get(act_type, 0) + 1\n",
    "                if activity_types:\n",
    "                    top_types = sorted(activity_types.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                    result += \"Most common activity types: \" + \\\n",
    "                        \", \".join([f\"{t[0]} ({t[1]})\" for t in top_types]) + \"\\n\"\n",
    "        except Exception:\n",
    "            pass  # Bioactivity optional\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error querying ChEMBL database for '{drug_name}': {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc026a68",
   "metadata": {},
   "source": [
    "### Exercise 2.4 – Create a Tools List\n",
    "\n",
    "Collect all of your tool functions into a single list called `TOOLS`. This list will be passed to the LLM so that it knows what tools are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a72970c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [calculator, lit_search, get_drug_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f429b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3 – Understanding LangGraph State\n",
    "\n",
    "A LangGraph **state** defines the data that flows through your agent. For chat agents, the state typically contains a list of messages which grows over the conversation. When creating a state schema, you use `TypedDict` to describe the keys and `Annotated` with reducer functions to specify how values should be updated. The `add_messages` reducer appends new messages rather than overwriting them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf42e1",
   "metadata": {},
   "source": [
    "### Exercise 3.1 – Define Chat State\n",
    "\n",
    "Define a `ChatState` class (subclassing `TypedDict`) with a single key `messages`. Use the `add_messages` reducer so that new messages are appended to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f573a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List, Dict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    \"\"\"The state schema for our LangGraph. It contains only a list of messages.\n",
    "\n",
    "    Messages are appended via the `add_messages` reducer to preserve the full conversation history. \n",
    "    Each message is represented as a dict with `role` and `content` keys (compatible with the OpenAI API message format).\"\"\"\n",
    "    messages: Annotated[List[Dict], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f000fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4 – Building the Agent Graph\n",
    "\n",
    "An agent graph describes how your agent processes messages. You will build a graph using **nodes** (functions) and **edges** (connections between functions). Nodes can be the chatbot itself or tool‑calling logic, and edges determine the execution flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2f68f",
   "metadata": {},
   "source": [
    "### Exercise 4.1 – Initialize Components\n",
    "\n",
    "1. Create a `StateGraph` instance using your `ChatState`.\n",
    "2. Initialise a chat model with `ChatOpenAI(model='gpt-4o', temperature=0)`.\n",
    "3. Bind your tools to the LLM using `bind_tools()`.\n",
    "4. Create a `ToolNode` from your tools list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cdadcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create graph builder using ChatState\n",
    "graph_builder = StateGraph(ChatState)\n",
    "\n",
    "# Initialise the chat model. Ensure your OpenAI API key is set in the .env file\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Bind the tools to the LLM so that it knows their schemas and how to construct tool calls in JSON\n",
    "llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "# Create a ToolNode using our tools list\n",
    "tool_node = ToolNode(tools=TOOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fc510",
   "metadata": {},
   "source": [
    "### Exercise 4.2 – Define the Chatbot Node\n",
    "\n",
    "Define a chatbot function that takes the state as input and returns a dictionary with a single key `messages`, containing the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4596d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def chatbot(state: ChatState) -> Dict[str, List]:\n",
    "    \"\"\"The main chatbot node. It invokes the LLM with the current messages.\"\"\"\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265e466",
   "metadata": {},
   "source": [
    "### Exercise 4.3 – Define the Routing Function\n",
    "\n",
    "Create a function `route_tools` that decides whether to call tools or terminate. If the most recent AI message contains tool calls (`tool_calls` attribute), route to the `'tools'` node; otherwise return `END`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34af01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(state: ChatState) -> str:\n",
    "    messages = state.get('messages', [])\n",
    "    ai_message = messages[-1] if messages else None\n",
    "    if ai_message and getattr(ai_message, 'tool_calls', []):\n",
    "        return 'tools'\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b54960",
   "metadata": {},
   "source": [
    "### Exercise 4.4 – Build the Complete Graph\n",
    "\n",
    "Assemble the agent graph by adding nodes and edges, then compile the graph into a runnable agent. Use `add_node()` for your chatbot and tool nodes, `add_conditional_edges()` for routing logic, and `add_edge()` to connect nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d27ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the chatbot node to the graph\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "\n",
    "# Add the tool node to the graph\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "# Add conditional edges from chatbot using the routing function\n",
    "graph_builder.add_conditional_edges('chatbot', route_tools, {'tools': 'tools', END: END})\n",
    "\n",
    "# Add edge from tools back to chatbot\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "\n",
    "# Add edge from START to chatbot\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "# Compile the graph into an agent\n",
    "agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1abcd",
   "metadata": {},
   "source": [
    "### Exercise 4.5 – Visualize Your Agent\n",
    "\n",
    "Use the graph's `draw_mermaid_png()` method to visualize the structure of your agent. This step is optional but helps you understand how nodes and edges connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "942675e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print('Graph visualization not available in this environment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf362da6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5 – Testing Your Agent\n",
    "\n",
    "Now that your agent graph is built, it's time to interact with it. Create a simple chat loop that greets the user, processes input until they type 'quit', and streams responses using `agent.stream()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83f916",
   "metadata": {},
   "source": [
    "### Exercise 5.1 – Create a Basic Chat Loop\n",
    "\n",
    "Write an interactive loop that:\n",
    "1. Greets the user and explains the agent's capabilities.\n",
    "2. Reads user input in a loop and exits on `'quit'`, `'exit'` or `'q'`.\n",
    "3. Creates the initial `state` with the user's message and streams the agent's responses via `agent.stream()`.\n",
    "4. Uses the `pretty_print()` method on messages to display nicely formatted output.\n",
    "\n",
    "\n",
    "Try out this chat loop with these three prompts: \n",
    "\n",
    "- **Prompt 1:** ” You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data. What is the mechanism of action of remdesivir and what bioactivity data is available for this compound?”\n",
    "\n",
    "\n",
    "- **Prompt 2:**  \" You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data. I'm investigating potential combination therapies for COVID-19. Can you help me understand the mechanisms of both hydroxychloroquine and azithromycin, then find recent literature discussing their combined use in COVID-19 treatment?”\n",
    "\n",
    "\n",
    "- **Prompt 3:**  \" You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data. I'm working on Alzheimer's drug discovery and need to evaluate aducanumab. Please provide detailed drug information including its development status, then search for recent publications about its clinical trial outcomes and any controversies surrounding its approval.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome to the LangGraph ReAct demo! Ask me a question.')\n",
    "print('I can perform simple math, look up drug information, and search PubMed via LitSense.')\n",
    "print('====================================================================')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input('User: ')\n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "    if not user_input or user_input.lower() in {'quit', 'exit', 'q'}:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    state = {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': user_input}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for event in agent.stream(state):\n",
    "        for value in event.values():\n",
    "            # The last message in the state is the AI response\n",
    "            msg = value[\"messages\"][-1]\n",
    "            # Use the built-in pretty_print method for better formatting\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcfa59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Part 6: Adding Short‑term Memory**\n",
    "\n",
    "To demonstrate the lack of memory in agent, please go back to Part 5, then perform these two prompts: \n",
    "\n",
    "- **Prompt 1:** My compound of interest is aspirin. Please remember this information.\n",
    "\n",
    "- **Prompt 2:** What is my interested compound?\n",
    "\n",
    "You will see when invoke **prompt 2**, the agent can not come up with the right answer - aspirin. It is because the GraphState is only maintained from START node to END node. After termination, every context from previous run is gone. Therefore, we need a component call Agent Memory to maintain context across runs.\n",
    "\n",
    "Memory allows your agent to remember previous parts of the conversation. LangGraph uses \"checkpointers\" to maintain state across interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80071d66",
   "metadata": {},
   "source": [
    "### Exercise 6.1 – Add Memory to Your Agent\n",
    "\n",
    "Rebuild your agent with memory by creating a new `StateGraph` that uses the same `ChatState`. Use an `InMemorySaver` to persist state across turns, and pass a configuration dictionary with a unique `thread_id` when streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "922def4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[List[Dict], add_messages]\n",
    "\n",
    "graph_builder = StateGraph(ChatState)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "def chatbot(state: ChatState) -> Dict[str, List]:\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "tool_node = ToolNode(tools=TOOLS)\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "graph_builder.add_conditional_edges('chatbot', route_tools, {'tools': 'tools', END: END})\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "saver = InMemorySaver()\n",
    "agent = graph_builder.compile(checkpointer=saver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc59c2e",
   "metadata": {},
   "source": [
    "### Exercise 6.2 – Create a Memory‑Enabled Chat Loop\n",
    "\n",
    "Write a chat loop similar to Part 5, but supply a `config` dictionary to `agent.stream()` containing a unique `thread_id` and `recursion_limit`. The same thread ID should be used for the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b60a5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config for memory\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'example_conversation',\n",
    "        'recursion_limit': 25\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af68cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome to the LangGraph ReAct demo with memory! Ask me a question.')\n",
    "print('I can perform simple math, look up drug information, and search PubMed via LitSense.')\n",
    "print('====================================================================')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input('User: ')\n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "    if not user_input or user_input.lower() in {'quit', 'exit', 'q'}:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    state = {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': user_input}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for event in agent.stream(state, config=config):\n",
    "        for value in event.values():\n",
    "            # The last message in the state is the AI response\n",
    "            msg = value[\"messages\"][-1]\n",
    "            # Use the built-in pretty_print method for better formatting\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037557d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7 – Prebuilt Agents\n",
    "\n",
    "LangGraph provides prebuilt agents that implement common architectures such as the ReAct pattern. These agents are quick to set up and let you focus on your tools and prompts rather than on graph wiring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a0d1b",
   "metadata": {},
   "source": [
    "### Exercise 7.1 – Create a Prebuilt Agent\n",
    "\n",
    "Use `create_react_agent` to instantiate a prebuilt ReAct agent. Provide your LLM, tools list, and a custom system prompt that instructs the agent how to behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=TOOLS,\n",
    "    prompt=(\n",
    "        \"You are an expert drug discovery researcher. Use your available tools to answer the user's question as accurately as possible. Never fabricate or invent data.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb6f7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8 – Extension Exercises\n",
    "\n",
    "I need some ideas here\n",
    "\n",
    "- System prompt (prompt template)\n",
    "- Output parser\n",
    "- Long-term memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d23b97",
   "metadata": {},
   "source": [
    "### Exercise 8.1 – Create a system prompt using a prompt template\n",
    "\n",
    "In LangGraph, you can provide a **system** or **instruction** message that sets the behaviour of the assistant before any user input is processed. LangGraph exposes this functionality via its `prompts` module. There you will find a few classes: `PromptTemplate` for formatting a single string, `ChatPromptTemplate` for building multi-message prompts, and `MessagesPlaceholder` for inserting a slot where conversation history will later be filled.\n",
    "\n",
    "In this exercise you will define a `ChatPromptTemplate` that begins with a system instruction. The system message should describe the assistant’s role (for example, instructing it to behave like a drug discovery researcher) and will be prepended to the user’s request before being passed to the agent.\n",
    "\n",
    "#### Prompt Template API References: https://python.langchain.com/docs/concepts/prompt_templates/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4244b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data.\"),\n",
    "    (\"user\", \"{request}\")\n",
    "])\n",
    "\n",
    "prompt_values = prompt_template.invoke({\"request\": \"What is the mechanism of action of remdesivir and what bioactivity data is available for this compound?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad830ca",
   "metadata": {},
   "source": [
    "`prompt_values` is a dictionary, which can be invoke directly to the agent. Try out by simple invoke the agent with the `prompt_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = agent.invoke(prompt_values, config=config)\n",
    "for msg in msgs['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09254490",
   "metadata": {},
   "source": [
    "### Exercise 8.2 – Integrate the system prompt with a streaming loop\n",
    "\n",
    "Building on the previous exercise, implement a multi-turn chat loop. Use a `while` loop to repeatedly accept user input, stream the agent’s response, and append both user and assistant messages to the conversation state.\n",
    "\n",
    "To include your system instruction in every turn, apply the `ChatPromptTemplate` from exercise 8.1 when constructing the input for the agent. When using the streaming API you must supply a `state` dictionary that includes a `'messages'` key. The value of this key should be a list of message dictionaries (each with `role` and `content` fields) representing the conversation history. As you loop, update this list to maintain the context across turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"example_conversation\",\n",
    "        \"recursion_limit\": 25,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data.\"),\n",
    "    (\"human\", \"{request}\"),\n",
    "])\n",
    "\n",
    "print(\"Welcome to the LangGraph ReAct demo with memory! Ask me a question.\")\n",
    "print(\"I can perform simple math, look up drug information, and search PubMed via LitSense.\")\n",
    "print(\"====================================================================\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "    if not user_input or user_input.lower() in {\"quit\", \"exit\", \"q\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Build the state as a dict with a messages list\n",
    "    prompt_value = prompt_template.invoke({\"request\": user_input})\n",
    "    state = {\"messages\": prompt_value.messages}\n",
    "\n",
    "    # Stream agent events\n",
    "    for event in agent.stream(state, config=config):\n",
    "        for value in event.values():\n",
    "            msg = value[\"messages\"][-1]\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e0962",
   "metadata": {},
   "source": [
    "## Exercise 9.1 - Structure Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac0995",
   "metadata": {},
   "source": [
    "Structured output parsers let you control the format of the language model’s responses. Instead of returning free‑form text, the model follows a schema (such as a Pydantic model) so that other components can reliably consume its output.\n",
    "\n",
    "- **Why?** Downstream software often expects data in a specific JSON schema (e.g. key–value pairs).\n",
    "- **How?** Define a Pydantic `BaseModel` to describe the fields you need, then use `with_structured_output(...)` to attach this schema to your LLM.\n",
    "\n",
    "You can read more in the [LangGraph structured output guide](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/#define-model-tools-and-graph-state).\n",
    "\n",
    "The diagram below shows the high‑level structure of the system we’re about to build. One LLM is responsible for deciding when to call tools, and a second LLM is tasked with formatting the final response according to your schema.\n",
    "\n",
    "<img src=\"images/react_structured_output.png\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7131f6",
   "metadata": {},
   "source": [
    "First we'll set up two language models:\n",
    "\n",
    "1. **Tool‑calling LLM**: This model can invoke the tools you defined earlier (calculator, literature search, etc.).\n",
    "2. **Structured output LLM**: This model will use a Pydantic schema to return the final answer as JSON with fields for drug names, justifications and sources.\n",
    "\n",
    "When we later ask a question such as *\"Use LitSearch literatures, give me 2 antiviral drugs that are potential to treat COVID‑19\"*, the agent will search PubMed via LitSense, find candidate antivirals, and then format its answer using this schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: create the tool-calling LLM\n",
    "llm = ChatOpenAI(model='gpt-5', temperature=0)\n",
    "llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "# Step 2: define a Pydantic schema describing the structured output we want\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DrugsInfo(BaseModel):\n",
    "    drugs: str = Field(description='a list of drug names')\n",
    "    justifications: str = Field(description='a list of justification for each drugs')\n",
    "    sources: str = Field(description='a list of citation for each drugs')\n",
    "\n",
    "# Step 3: create the structured output LLM\n",
    "llm = ChatOpenAI(model='gpt-5', temperature=0)\n",
    "llm_with_structured_outputs = llm.with_structured_output(DrugsInfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c144fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import Dict, List\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Define the chatbot node: this function invokes the tool‑calling LLM and appends the AI message to state\n",
    "def chatbot(state: ChatState) -> Dict[str, List]:\n",
    "    \"\"\"The main chatbot node. It invokes the LLM with the current messages.\"\"\"\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "# Define the respond node: this function uses the structured‑output LLM to format the final answer\n",
    "def respond(state: ChatState):\n",
    "    # Extract only the content of each message for the structured LLM\n",
    "    response = llm_with_structured_outputs.invoke(\n",
    "        [HumanMessage(content=state[\"messages\"][i].content) for i in range(len(state[\"messages\"]))]\n",
    "    )\n",
    "    # Wrap the structured JSON as an AIMessage and return it\n",
    "    return {\"messages\": [AIMessage(content=response.model_dump_json())]}\n",
    "\n",
    "# Define a simple routing function to decide whether to keep calling tools or format a final response\n",
    "def should_continue(state: ChatState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the last message does not contain a tool call, we are ready to format a response\n",
    "    if not last_message.tool_calls:\n",
    "        return \"respond\"\n",
    "    # Otherwise, continue invoking tools\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Build the state graph\n",
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "# Add the nodes: chatbot (for reasoning/tool calls), respond (for final formatting), and the existing tool node\n",
    "workflow.add_node(\"chatbot\", chatbot)\n",
    "workflow.add_node(\"respond\", respond)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point: we start by invoking the chatbot node\n",
    "workflow.set_entry_point(\"chatbot\")\n",
    "\n",
    "# Add conditional edges: route to either tools or respond depending on should_continue\n",
    "workflow.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"respond\": \"respond\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# After calling tools, loop back to the chatbot; after responding, end the workflow\n",
    "workflow.add_edge(\"tools\", \"chatbot\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "# Compile the workflow into an executable agent\n",
    "agent = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b827f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print('Graph visualization not available in this environment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0605e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the agent a question and pretty‑print the structured response\n",
    "answer = agent.invoke({'messages': 'Use LitSearch literatures, give me 2 antiviral drugs that are potential to treat COVID-19'})\n",
    "answer['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd59a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Nodes** are functions that operate on state.\n",
    "- **Edges** define the flow between nodes.\n",
    "- **State** carries data through the agent. Use reducer functions such as `add_messages` to control how state is updated【78264805686364†L107-L148】.\n",
    "- **Tools** extend agent capabilities and are annotated with `@tool`.\n",
    "- **Memory** allows agents to maintain context across invocations.\n",
    "- **Prebuilt agents** provide quick solutions for common patterns but offer less control than a custom graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa566d4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **LangGraph Documentation** – https://langchain-ai.github.io/langgraph/\n",
    "- **LangGraph Quickstart and Tutorials** – Build a basic chatbot (https://langchain-ai.github.io/langgraph/tutorials/get-started/1-build-basic-chatbot/)\n",
    "- **LangChain Tools** – https://python.langchain.com/docs/integrations/tools/\n",
    "- **ChEMBL Web Services** – https://chembl.gitbook.io/chembl-interface-documentation/web-services\n",
    "- **OpenAI API** – https://platform.openai.com/docs/\n",
    "\n",
    "These references can help you explore LangGraph and related libraries beyond the scope of this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5952c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**🎉 Congratulations! You've built your first AI agent with LangGraph!**\n",
    "\n",
    "Feel free to modify and extend your agent. You can experiment with new tools, different LLMs, and additional nodes to create even more capable and personalised agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
