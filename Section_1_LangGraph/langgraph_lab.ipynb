{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41992144",
   "metadata": {},
   "source": [
    "<img src=\"images/scilife_logo.png\" width=\"400\">\n",
    "<img src=\"images/essence_logo.png\" width=\"300\">\n",
    "\n",
    "# SciLifeLab Workshop - Hands-on Section: LangGraph \"Hello World\"\n",
    "\n",
    "\n",
    "\n",
    "Welcome to this hands‑on lab session on building AI Agents with **LangGraph**! \n",
    "\n",
    "LangGraph is a low‑level orchestration framework for constructing stateful AI workflows using graphs. LangGraph provides several key benefits for agentic AI applications, including durable execution, support for human‑in‑the‑loop workflows, comprehensive memory (both short‑ and long‑term), built‑in debugging, and production‑ready deployment features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a60e0",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "By the end of this workshop, you will:\n",
    "- Understand core concepts of LangGraph (tools, nodes, edges, state, and memory).\n",
    "- Create and integrate your own tools for an AI agent.\n",
    "- Build a ReAct‑style agent using an LLM and custom tools.\n",
    "- Implement agent memory to maintain conversational context.\n",
    "- Compare custom agents with prebuilt LangGraph agents.\n",
    "- Explore extension tasks such as custom graph, structured output, and prompts template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841aa80a",
   "metadata": {},
   "source": [
    "## Workshop Outline \n",
    "- **Part 1**: Setup & imports\n",
    "- **Part 2**: Understanding and creating tools\n",
    "- **Part 3**: Defining the state\n",
    "- **Part 4**: Building the agent graph\n",
    "- **Part 5**: Testing the agent\n",
    "- **Part 6**: Adding short‑term memory\n",
    "- **Part 7**: Exploring prebuilt agents\n",
    "- **Part 8 (optional)**: Extension exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70033f32",
   "metadata": {},
   "source": [
    "## Instructions for Participants\n",
    "\n",
    "**Throughout this lab, look for `TODO` comments and `...` placeholders in the code cells. These indicate where you need to add your implementation.** \n",
    "\n",
    "Your task is to:\n",
    "1. Replace `...` placeholders with appropriate code\n",
    "2. Follow the instructions in `TODO` comments \n",
    "3. Refer to the exercise descriptions and API references provided\n",
    "4. Use the `test cell` right below each `TODO` cell to validate your solutions\n",
    "\n",
    "**Tip:** Each exercise builds on the previous one, so complete them in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba369",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 – Setup\n",
    "\n",
    "In this first step, we'll import the necessary dependencies and load any environment variables. Make sure your API keys (e.g., OpenAI) are stored in a `.env` file in the same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a6198",
   "metadata": {},
   "source": [
    "### Exercise 1.1 – Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any packages you need here\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8cdae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 – Understanding and Creating Tools\n",
    "\n",
    "In LangGraph, **tools** are Python functions that extend your agent's capabilities beyond text generation. They can call external APIs or perform computations, and are annotated with the `@tool` decorator from LangChain. A tool takes typed inputs and returns a string; the LLM can decide when to call a tool.\n",
    "\n",
    "When designing tools for agents, there are two important considerations: \n",
    "- **Input - Output**: It is similar to when designing a Python function, but the input is now handled by generated content from LLM. Output should be parsed to feed meaningful context for the agent context \n",
    "\n",
    "- **Description**: The `@tool` decorator requires docstrings from a Python function and will use it as the tool's description. These descriptions will feed the LLM system prompts, making it aware of these existing tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fac64e",
   "metadata": {},
   "source": [
    "### About the task\n",
    "\n",
    "In this exercise, we will develop three tools useful for the drug discovery domain.\n",
    "\n",
    "**1. Calculator:** a tool to execute mathematical expressions\n",
    "\n",
    "**2. LitSearch:** a tool to perform semantic search on all publications available on PubMed\n",
    "\n",
    "**3. GetDrugInfo:** a tool to retrieve drug information given the drug name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdab0e4",
   "metadata": {},
   "source": [
    "### Exercise 2.1 – Create a Calculator Tool\n",
    "\n",
    "Write a tool that evaluates simple arithmetic expressions (e.g. `'2 + 3 * 4'`). \n",
    "\n",
    "Instruction: \n",
    "- Use Python's built‑in `eval` to perform the calculation.\n",
    "- Your tool should accept a `string` input called `expression` and return a `string` result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe36555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# TODO: establish calculator tool\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a simple arithmetic expression (e.g. '2 + 3 * 4').\n",
    "    \n",
    "    Args:\n",
    "        expression (str): A string containing a valid arithmetic expression (e.g., \"2 + 3 * 4\").\n",
    "    Returns:\n",
    "        result (str): The result of evaluating the expression, converted to a string.\"\"\"\n",
    "    return \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1698e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 2.1\n",
    "try:\n",
    "    # ensure calculator returns correct result for simple expressions\n",
    "    assert callable(calculator), \"calculator must be callable\"\n",
    "    result1 = calculator(\"2 + 3 * 4\")\n",
    "    assert isinstance(result1, str), \"calculator should return a string\"\n",
    "    assert result1.strip() == \"14\", f\"Expected '14', got {result1}\"\n",
    "    # check error handling\n",
    "    err_result = calculator(\"2 +\")\n",
    "    assert isinstance(err_result, str) and (\"error\" in err_result.lower() or \"invalid\" in err_result.lower()), \"Calculator should return an error string on invalid input\"\n",
    "    print(\"Calculator tool tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"Calculator tool tests failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e830fbe",
   "metadata": {},
   "source": [
    "### Exercise 2.2 – Create a Literature Search Tool\n",
    "\n",
    "Use the **LitSense** API to perform semantic search of PubMed articles. Your tool should accept a `query` string and an optional `limit` integer. \n",
    "\n",
    "Below is the API reference of LitSense Wrapper.\n",
    "\n",
    "<img src=\"./images/LitSense_API.png\" width=\"800\">\n",
    "\n",
    "\n",
    "### **References**\n",
    "LitSense: https://academic.oup.com/nar/article/53/W1/W361/8133630\n",
    "\n",
    "Github: https://github.com/DinhLongHuynh/LitSense_Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "61a2613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from utils.litsense import LitSense_API\n",
    "\n",
    "@tool\n",
    "def lit_search(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Retrieve information from PubMed using a semantic search via the LitSense API.\\n\\n\n",
    "    Args:\n",
    "        query: The research question or topic to search for in PubMed literature.\n",
    "        limit: Maximum number of results to return (default is 5).\n",
    "    Returns:\n",
    "        result (str): A formatted string containing semantically relevant passages from PubMed articles, including PMID and content only.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: establish engine and get the results given query\n",
    "    engine = ...\n",
    "    results = ...\n",
    "\n",
    "    # Parse result into prefered format\n",
    "    result_str = \"\"\n",
    "    for i, result in enumerate(results):\n",
    "        result_str += (\n",
    "                f\"\\n--- Passage #{i+1} ---\\n\"\n",
    "                f\"PMID: {result.pmid}\\n\"\n",
    "                f\"Content: {result.text}\\n\"\n",
    "            )\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4924fc3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 2.2 \n",
    "try:\n",
    "    class _DummyResult:\n",
    "        def __init__(self, pmid, text):\n",
    "            self.pmid = pmid\n",
    "            self.text = text\n",
    "\n",
    "    class _DummyEngine:\n",
    "        def __init__(self):\n",
    "            self.retrieve_called = False\n",
    "            self.last_args = None\n",
    "        def retrieve(self, query, limit=5):\n",
    "            self.retrieve_called = True\n",
    "            self.last_args = (query, limit)\n",
    "            return [_DummyResult('PMID1', 'Sample text 1'), _DummyResult('PMID2', 'Sample text 2')]\n",
    "\n",
    "    target_callable = getattr(lit_search, 'func', lit_search)\n",
    "    func_globals = getattr(target_callable, '__globals__', None)\n",
    "    assert func_globals is not None, 'lit_search callable must expose globals for patching'\n",
    "\n",
    "    import utils.litsense as litsense_module\n",
    "    has_global_cls = 'LitSense_API' in func_globals\n",
    "    original_cls_global = func_globals.get('LitSense_API')\n",
    "    original_cls_module = getattr(litsense_module, 'LitSense_API', None)\n",
    "    dummy_engine_instance = _DummyEngine()\n",
    "    res = None\n",
    "\n",
    "    func_globals['LitSense_API'] = lambda: dummy_engine_instance\n",
    "    if original_cls_module is not None:\n",
    "        litsense_module.LitSense_API = lambda: dummy_engine_instance\n",
    "\n",
    "    try:\n",
    "        call_kwargs = {'query': 'test query', 'limit': 2}\n",
    "        if hasattr(lit_search, 'invoke'):\n",
    "            res = lit_search.invoke(call_kwargs)\n",
    "        elif hasattr(lit_search, 'run'):\n",
    "            try:\n",
    "                res = lit_search.run(call_kwargs)\n",
    "            except TypeError:\n",
    "                res = lit_search.run('test query')\n",
    "        else:\n",
    "            res = lit_search(**call_kwargs)\n",
    "    finally:\n",
    "        if has_global_cls:\n",
    "            func_globals['LitSense_API'] = original_cls_global\n",
    "        else:\n",
    "            func_globals.pop('LitSense_API', None)\n",
    "        if original_cls_module is not None:\n",
    "            litsense_module.LitSense_API = original_cls_module\n",
    "\n",
    "    assert dummy_engine_instance.retrieve_called, 'lit_search should call LitSense_API.retrieve'\n",
    "    assert dummy_engine_instance.last_args == ('test query', 2), 'lit_search should pass query and limit to retrieve'\n",
    "    assert isinstance(res, str), 'lit_search should return a formatted string'\n",
    "    assert 'PMID:' in res and 'Content:' in res, 'Result should include PMID and Content fields'\n",
    "    print('Literature search tool tests passed!')\n",
    "except Exception as e:\n",
    "    raise AssertionError(f'Literature search tool tests failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bfff2a",
   "metadata": {},
   "source": [
    "### Exercise 2.3 – Create a Drug Information Tool\n",
    "\n",
    "Build a tool that queries the **ChEMBL** database for comprehensive drug information. Use the `chembl_webresource_client` to search for molecules by name or synonym. If you find multiple candidates, select the first one. Return a formatted string containing the molecule's name, mechanism of action, and therapeutic indications.\n",
    "\n",
    "Due to the complexity of the API endpoint, we decided to give you the full script for this tool so you could focus on building an agent with LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2bcac328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "\n",
    "@tool\n",
    "def get_drug_info(drug_name: str) -> str:\n",
    "    \"\"\"Retrieve comprehensive drug information using the ChEMBL database (supports synonyms).\n",
    "    \n",
    "    Args:\n",
    "        drug_name (str): the drug name of interest\n",
    "    Returns:\n",
    "        result (str): A formatted string containing drug information from ChEMBL.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Search for the molecule - get only first result\n",
    "        search_results = new_client.molecule.search(drug_name)\n",
    "        \n",
    "        try:\n",
    "            candidate = next(iter(search_results))\n",
    "        except StopIteration:\n",
    "            return f\"No information found for '{drug_name}'\"\n",
    "\n",
    "        chembl_id = candidate['molecule_chembl_id']\n",
    "        \n",
    "        # Get molecule details (single API call)\n",
    "        details = new_client.molecule.get(chembl_id)\n",
    "\n",
    "        # Build base result string\n",
    "        pref_name = details.get('pref_name') or candidate.get('pref_name') or drug_name\n",
    "        result = f\"**{pref_name}** (ChEMBL ID: {chembl_id})\\n\"\n",
    "        result += f\"Type: {details.get('molecule_type', 'Not specified')}\\n\"\n",
    "\n",
    "        # Add molecular formula if available\n",
    "        mol_props = details.get('molecule_properties') or {}\n",
    "        if mol_props.get('molecular_formula'):\n",
    "            result += f\"Molecular Formula: {mol_props['molecular_formula']}\\n\"\n",
    "\n",
    "        # Add synonyms - already in details\n",
    "        synonyms = details.get('molecule_synonyms') or []\n",
    "        if synonyms:\n",
    "            result += \"\\n**Synonyms/Trade names:**\\n\"\n",
    "            seen = set()\n",
    "            count = 0\n",
    "            for syn in synonyms:\n",
    "                if count >= 8:  # Limit to 8 synonyms\n",
    "                    break\n",
    "                name = syn.get('molecule_synonym') or syn.get('synonyms')\n",
    "                if name and name.lower() != pref_name.lower() and name not in seen:\n",
    "                    seen.add(name)\n",
    "                    result += f\"- {name}\\n\"\n",
    "                    count += 1\n",
    "\n",
    "        # Fetch mechanisms - limited to 3\n",
    "        try:\n",
    "            mechs = new_client.mechanism.filter(\n",
    "                molecule_chembl_id=chembl_id\n",
    "            ).only(['mechanism_of_action'])[:3]\n",
    "            mechanism_list = list(mechs)\n",
    "            \n",
    "            if mechanism_list:\n",
    "                result += \"\\n**Mechanism of Action:**\\n\"\n",
    "                seen_moa = set()\n",
    "                for mech in mechanism_list:\n",
    "                    moa = mech.get('mechanism_of_action')\n",
    "                    if moa and moa not in seen_moa:\n",
    "                        seen_moa.add(moa)\n",
    "                        result += f\"- {moa}\\n\"\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Fetch indications - limited to 6\n",
    "        try:\n",
    "            inds = new_client.drug_indication.filter(\n",
    "                molecule_chembl_id=chembl_id\n",
    "            ).only(['efo_term', 'mesh_heading', 'max_phase_for_ind'])[:6]\n",
    "            indication_list = list(inds)\n",
    "            \n",
    "            if indication_list:\n",
    "                result += \"\\n**Indications:**\\n\"\n",
    "                seen_ind = set()\n",
    "                for ind in indication_list:\n",
    "                    indication_name = ind.get('efo_term') or ind.get('mesh_heading')\n",
    "                    if indication_name and indication_name not in seen_ind:\n",
    "                        seen_ind.add(indication_name)\n",
    "                        max_phase = ind.get('max_phase_for_ind')\n",
    "                        phase_info = f\" (Phase {max_phase})\" if max_phase else \"\"\n",
    "                        result += f\"- {indication_name}{phase_info}\\n\"\n",
    "            else:\n",
    "                result += \"\\nNo indication data available.\\n\"\n",
    "        except:\n",
    "            result += \"\\nNo indication data available.\\n\"\n",
    "\n",
    "        # Fetch activities - limited to 30\n",
    "        try:\n",
    "            acts = new_client.activity.filter(\n",
    "                molecule_chembl_id=chembl_id\n",
    "            ).only(['standard_type'])[:30]\n",
    "            activity_list = list(acts)\n",
    "            \n",
    "            if activity_list:\n",
    "                result += f\"\\n**Bioactivity Data:** {len(activity_list)}+ records\\n\"\n",
    "                activity_types = {}\n",
    "                for act in activity_list:\n",
    "                    act_type = act.get('standard_type')\n",
    "                    if act_type:\n",
    "                        activity_types[act_type] = activity_types.get(act_type, 0) + 1\n",
    "                if activity_types:\n",
    "                    top_types = sorted(activity_types.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "                    result += \"Top types: \" + \", \".join([f\"{t[0]} ({t[1]})\" for t in top_types]) + \"\\n\"\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error querying ChEMBL database for '{drug_name}': {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc026a68",
   "metadata": {},
   "source": [
    "### Exercise 2.4 – Create a Tools List\n",
    "\n",
    "Collect all of your tool functions into a single list called `TOOLS`. This list will be passed to the LLM so it is aware of the available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a72970c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a list of tools\n",
    "TOOLS = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76543715",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 2.4 \n",
    "try:\n",
    "    assert isinstance(TOOLS, list), \"TOOLS should be a list\"\n",
    "    # Extract names from tool objects; decorated tools expose a 'name' attribute\n",
    "    tool_names = set()\n",
    "    for t in TOOLS:\n",
    "        name = getattr(t, 'name', None)\n",
    "        if name is None:\n",
    "            # Fallback to function name\n",
    "            name = getattr(t, '__name__', None)\n",
    "        tool_names.add(name)\n",
    "    expected = {'calculator', 'lit_search', 'get_drug_info'}\n",
    "    assert expected.issubset(tool_names), f\"TOOLS should contain calculator, lit_search, and get_drug_info. Found {tool_names}\"\n",
    "    print(\"TOOLS list tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"TOOLS list tests failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f429b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3 – Understanding LangGraph State\n",
    "\n",
    "For agents, the state typically contains a list of messages that **grows over** the conversation. \n",
    "\n",
    "When creating a state schema, you use:\n",
    "\n",
    "- `TypedDict` to describe the keys.\n",
    "- `Annotated` with updating functions to specify how values should be updated. \n",
    "- `add_messages` is one updating function. It appends new messages rather than overwriting them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf42e1",
   "metadata": {},
   "source": [
    "### Exercise 3.1 – Define Chat State\n",
    "\n",
    "Instruction: \n",
    "- Define a `ChatState` class (subclassing `TypedDict`) with a single key `messages`. \n",
    "- Use the `add_messages` updating function so that new messages are appended to the state.\n",
    "\n",
    "Below is the API reference of `ChatState`.\n",
    "\n",
    "<img src=\"images/ChatState.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f573a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List, Dict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# TODO: define graph state\n",
    "class ChatState(...):\n",
    "    \"\"\"The state schema for our LangGraph. It contains only a list of messages.\n",
    "\n",
    "    Messages are appended via the `add_messages` to preserve the full conversation history.\"\"\"\n",
    "    messages: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb2ebe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 3.1\n",
    "try:\n",
    "    from typing import get_origin\n",
    "    assert isinstance(ChatState, type), \"ChatState should be a class\"\n",
    "    assert 'messages' in getattr(ChatState, '__annotations__', {}), \"ChatState should define a 'messages' field\"\n",
    "    annotation = ChatState.__annotations__['messages']\n",
    "    # Check that the annotation uses Annotated with add_messages metadata\n",
    "    # For Annotated types, __metadata__ holds metadata\n",
    "    has_metadata = hasattr(annotation, '__metadata__')\n",
    "    assert has_metadata, \"ChatState.messages should be Annotated to include add_messages metadata\"\n",
    "    # Verify the metadata includes add_messages\n",
    "    from langgraph.graph.message import add_messages\n",
    "    metadata = annotation.__metadata__\n",
    "    assert add_messages in metadata, \"ChatState.messages Annotated metadata should include add_messages\"\n",
    "    print(\"ChatState definition tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"ChatState definition tests failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f000fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4 – Building the Agent Graph\n",
    "\n",
    "This is the graph we are going to create: \n",
    "\n",
    "<img src=\"images/react_agent.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2f68f",
   "metadata": {},
   "source": [
    "### Exercise 4.1 – Initialize Components\n",
    "\n",
    "Instruction: \n",
    "- Initialise a `StateGraph` instance using your `ChatState`.\n",
    "- Initialise a chat model with `ChatOpenAI(model='gpt-4o', temperature=0)`.\n",
    "- Bind your tools to the LLM using `bind_tools()` so that the LLMS knows tools' schemas and how to construct tool calls\n",
    "- Create a `ToolNode` from your tools list. This class serves as a wrapper for the tools and should implement all necessary methods, including parsing the LLM's output, managing the tool schemas, and handling the output from the tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdadcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# TODO: initialize graph builder using ChatState\n",
    "graph_builder = ...\n",
    "\n",
    "# TODO: Initialise the chat model. Ensure your OpenAI API key is set in the .env file\n",
    "llm = ChatOpenAI(model='...', temperature=0)\n",
    "\n",
    "# TODO: Bind the tools to the LLM so that it knows their schemas and how to construct tool calls in JSON\n",
    "llm_with_tools = llm.bind_tools(...)\n",
    "\n",
    "# TODO: Create a ToolNode using our tools list\n",
    "tool_node = ToolNode(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36070e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4.1\n",
    "try:\n",
    "    from langgraph.graph import StateGraph\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langgraph.prebuilt import ToolNode\n",
    "    assert isinstance(graph_builder, StateGraph), \"graph_builder should be an instance of StateGraph\"\n",
    "    assert isinstance(llm, ChatOpenAI), \"llm should be an instance of ChatOpenAI\"\n",
    "    # llm_with_tools should expose an invoke method\n",
    "    assert hasattr(llm_with_tools, 'invoke'), \"llm_with_tools should have an invoke method\"\n",
    "    assert isinstance(tool_node, ToolNode), \"tool_node should be an instance of ToolNode\"\n",
    "    print(\"Initialization tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"Initialization tests failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fc510",
   "metadata": {},
   "source": [
    "### Exercise 4.2 – Define the Chatbot Node\n",
    "\n",
    "Define a chatbot function that takes the `state` as input and returns a dictionary with a single key `messages`.\n",
    "\n",
    "When invoke the LLM, we provide it with all the `messages` in `state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4596d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# TODO: define chatbot node\n",
    "def chatbot(state: ChatState) -> Dict[str, List]:\n",
    "    \"\"\"The main chatbot node. It invokes the LLM with the current messages.\"\"\"\n",
    "    return {'messages': [llm_with_tools.invoke(...)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d197c3f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4.2\n",
    "try:\n",
    "    assert callable(chatbot), 'chatbot should be callable'\n",
    "\n",
    "    class _DummyLLM:\n",
    "        def __init__(self):\n",
    "            self.called = False\n",
    "            self.last_messages = None\n",
    "            self.response = 'dummy_response'\n",
    "        def invoke(self, messages):\n",
    "            self.called = True\n",
    "            self.last_messages = messages\n",
    "            return self.response\n",
    "\n",
    "    target_callable = getattr(chatbot, '__wrapped__', chatbot)\n",
    "    func_globals = getattr(target_callable, '__globals__', None)\n",
    "    assert func_globals is not None, 'chatbot callable must expose globals for patching'\n",
    "\n",
    "    had_original_llm = 'llm_with_tools' in func_globals\n",
    "    original_llm = func_globals.get('llm_with_tools')\n",
    "    dummy_llm = _DummyLLM()\n",
    "    func_globals['llm_with_tools'] = dummy_llm\n",
    "\n",
    "    try:\n",
    "        test_state = {'messages': ['hello']}\n",
    "        result = chatbot(test_state)\n",
    "    finally:\n",
    "        if had_original_llm:\n",
    "            func_globals['llm_with_tools'] = original_llm\n",
    "        else:\n",
    "            func_globals.pop('llm_with_tools', None)\n",
    "\n",
    "    assert dummy_llm.called, 'chatbot should call llm_with_tools.invoke'\n",
    "    assert dummy_llm.last_messages == test_state['messages'], 'chatbot should pass the current state messages to the LLM'\n",
    "    assert isinstance(result, dict) and 'messages' in result, \"chatbot should return a dict with a 'messages' key\"\n",
    "    assert isinstance(result['messages'], list) and result['messages'], 'chatbot should return a non-empty messages list'\n",
    "    assert result['messages'][0] == dummy_llm.response, 'chatbot should include the LLM response inside the messages list'\n",
    "    print('Chatbot node tests passed!')\n",
    "except Exception as e:\n",
    "    raise AssertionError(f'Chatbot node tests failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265e466",
   "metadata": {},
   "source": [
    "### Exercise 4.3 – Define the Routing Function\n",
    "\n",
    "Create a function `route_tools` that decides whether to call tools or terminate. \n",
    "\n",
    "- Step 1: Extract the last message from `state`.\n",
    "- Step 2: If the last message contains tool calls (`tool_calls` attribute), return `'tools'`; otherwise return `END`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define router function\n",
    "def route_tools(state: ChatState) -> str:\n",
    "    last_message = ...\n",
    "    if getattr(last_message, ..., []):\n",
    "        return ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024deda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4.3\n",
    "try:\n",
    "    assert callable(route_tools), 'route_tools should be callable'\n",
    "\n",
    "    class _Msg:\n",
    "        def __init__(self, tool_calls=None):\n",
    "            self.tool_calls = tool_calls or []\n",
    "\n",
    "    state_with_tools = {'messages': [_Msg(tool_calls=['call'])]}\n",
    "    tool_branch = route_tools(state_with_tools)\n",
    "\n",
    "    state_without_tools = {'messages': [_Msg(tool_calls=[])]}\n",
    "    no_tool_branch = route_tools(state_without_tools)\n",
    "\n",
    "    state_empty = {'messages': []}\n",
    "    empty_branch = route_tools(state_empty)\n",
    "\n",
    "    valid_tool_returns = {'tools', 'continue'}\n",
    "    valid_end_returns = {'END', 'respond'}\n",
    "\n",
    "    assert isinstance(tool_branch, str), 'route_tools should return a string when tools are requested'\n",
    "    assert tool_branch in valid_tool_returns, \"route_tools should return 'tools' or 'continue' when a tool call is present\"\n",
    "    for branch, label in [(no_tool_branch, 'no tool calls'), (empty_branch, 'no messages')]:\n",
    "        assert isinstance(branch, str), f'route_tools should return a string when {label}'\n",
    "        assert branch in valid_end_returns, \"route_tools should return 'END' or 'respond' when no tool call is present\"\n",
    "    print('Routing function tests passed!')\n",
    "except Exception as e:\n",
    "    raise AssertionError(f'Routing function tests failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b54960",
   "metadata": {},
   "source": [
    "### Exercise 4.4 – Build the Complete Graph\n",
    "\n",
    "Assemble the agent graph by adding nodes and edges, then compile the graph into a runnable agent. Use `add_node()` for your chatbot and tool nodes, `add_conditional_edges()` for routing logic, and `add_edge()` to connect nodes.\n",
    "\n",
    "\n",
    "<img src=\"images/graph_create_1.png\" width=\"800\">\n",
    "\n",
    "<img src=\"images/graph_create_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(ChatState)\n",
    "\n",
    "# TODO: Add the chatbot node to the graph\n",
    "graph_builder.add_node(...)\n",
    "\n",
    "# TODO: Add the tool node to the graph\n",
    "graph_builder.add_node(...)\n",
    "\n",
    "# TODO: Add conditional edges from chatbot to either tools or END using the routing function\n",
    "graph_builder.add_conditional_edges(...)\n",
    "\n",
    "# TODO: Add edge from tools back to chatbot\n",
    "graph_builder.add_edge(...)\n",
    "\n",
    "# TODO: Add edge from START to chatbot\n",
    "graph_builder.add_edge(...)\n",
    "\n",
    "# TODO: Compile the graph into an agent\n",
    "agent = graph_builder.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88a008",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4.4 \n",
    "try:\n",
    "    from langgraph.graph import START, END\n",
    "    assert 'agent' in globals(), 'agent should be defined after building the graph'\n",
    "    graph = agent.get_graph()\n",
    "    node_names = set(graph.nodes)\n",
    "    assert START in node_names and END in node_names, 'Compiled graph should include START and END nodes'\n",
    "    assert {'chatbot', 'tools'}.issubset(node_names), \"Graph should contain 'chatbot' and 'tools' nodes\"\n",
    "\n",
    "    edges = {(edge.source, edge.target, edge.data) for edge in graph.edges}\n",
    "    assert (START, 'chatbot', None) in edges, \"Graph should start at 'chatbot' from START\"\n",
    "    assert ('chatbot', 'tools', None) in edges, \"Graph should route from 'chatbot' to 'tools' when tool calls are present\"\n",
    "    assert ('chatbot', END, 'END') in edges, \"Graph should allow terminating at END from 'chatbot'\"\n",
    "    assert ('tools', 'chatbot', None) in edges, \"Graph should loop from 'tools' back to 'chatbot'\"\n",
    "    print('Graph construction tests passed!')\n",
    "except Exception as e:\n",
    "    raise AssertionError(f'Graph construction tests failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1abcd",
   "metadata": {},
   "source": [
    "### Exercise 4.5 – Visualize Your Agent\n",
    "\n",
    "Use the graph's `draw_mermaid_png()` method to visualize the structure of your agent. This step is optional but helps you understand how nodes and edges connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942675e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf362da6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5 – Testing Your Agent\n",
    "\n",
    "Now that your agent graph is built, it's time to interact with it. Create a simple chat loop that greets the user, processes input until they type 'quit', and streams responses using `agent.stream()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83f916",
   "metadata": {},
   "source": [
    "### Exercise 5.1 – Create a Basic Chat Loop\n",
    "\n",
    "Write an interactive loop that:\n",
    "1. Greets the user and explains the agent's capabilities.\n",
    "2. Reads user input in a loop and exits on `'quit'`, `'exit'` or `'q'`.\n",
    "3. Creates the initial `state` with the user's message and streams the agent's responses via `agent.stream()`.\n",
    "4. Uses the `pretty_print()` method on messages to display nicely formatted output.\n",
    "\n",
    "\n",
    "Try out this chat loop with these three prompts: \n",
    "\n",
    "- **Prompt 1:** ” You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data. What is the mechanism of action of remdesivir and what bioactivity data is available for this compound?”\n",
    "\n",
    "\n",
    "- **Prompt 2:**  \" You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data. I'm investigating potential combination therapies for COVID-19. Can you help me understand the mechanisms of both hydroxychloroquine and azithromycin, then find recent literature discussing their combined use in COVID-19 treatment?”\n",
    "\n",
    "\n",
    "- **Prompt 3:**  \" You are an expert drug discovery researcher. Use your available tools to answer the user’s question as accurately as possible. Never fabricate or invent data. I'm working on Alzheimer's drug discovery and need to evaluate aducanumab. Please provide detailed drug information including its development status, then search for recent publications about its clinical trial outcomes and any controversies surrounding its approval.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome to the LangGraph ReAct demo with memory! Ask me a question.')\n",
    "print('I can perform simple math, look up drug information, and search PubMed via LitSense.')\n",
    "print('====================================================================')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Get input prompt from user\n",
    "        user_input = input('User: ')\n",
    "    except EOFError:\n",
    "        break\n",
    "    \n",
    "    # If input contains one of three keywords: quit, exit, and q; exit the streaming process.\n",
    "    if not user_input or user_input.lower() in {'quit', 'exit', 'q'}:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    # Initialize graph state with user's input\n",
    "    state = {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': user_input}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    # Print the user's message first\n",
    "    print(f\"\"\"================================== User's Message ==================================\n",
    "{user_input}\n",
    "    \"\"\")\n",
    "    # Stream the answer from agent\n",
    "    for event in agent.stream(state):\n",
    "        for value in event.values():\n",
    "            # The last message in the state is the AI response\n",
    "            msg = value[\"messages\"][-1]\n",
    "            # Use the built-in pretty_print method for better formatting\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcfa59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Adding Short‑term Memory\n",
    "\n",
    "To demonstrate the lack of memory in the agent, please go back to Part 5, then perform these two prompts: \n",
    "\n",
    "- **Prompt 1:** My compound of interest is aspirin. Please remember this information.\n",
    "\n",
    "- **Prompt 2:** What is my interesting compound?\n",
    "\n",
    "You will see when invoking **prompt 2**, the agent can not come up with the correct answer - aspirin. This is because the GraphState is only maintained from the START node to the END node. After termination, all contexts from the previous run are lost. Therefore, we need a component called Agent Memory to maintain context across runs.\n",
    "\n",
    "Memory allows your agent to remember previous parts of the conversation. LangGraph uses \"checkpointers\" to maintain state across interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80071d66",
   "metadata": {},
   "source": [
    "### Exercise 6.1 – Add Memory to Your Agent\n",
    "\n",
    "Rebuild your agent with memory by creating a new `StateGraph` that uses the same `ChatState`. \n",
    "\n",
    "Initialize `checkpointer` with `InMemorySaver` to persist state across turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922def4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[List[Dict], add_messages]\n",
    "\n",
    "graph_builder = StateGraph(ChatState)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "def chatbot(state: ChatState) -> Dict[str, List]:\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "tool_node = ToolNode(tools=TOOLS)\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "graph_builder.add_conditional_edges('chatbot', route_tools, {'tools': 'tools', END: END})\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "\n",
    "# TODO: Add checkpointer to the agent\n",
    "checkpointer = ...\n",
    "agent = graph_builder.compile(checkpointer=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081e537",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 6.1\n",
    "try:\n",
    "    from langgraph.checkpoint.memory import InMemorySaver\n",
    "    # Determine which variable holds the checkpointer\n",
    "    cp = None\n",
    "    for name in ['checkpointer', 'saver']:\n",
    "        if name in globals():\n",
    "            cp = globals()[name]\n",
    "            break\n",
    "    assert cp is not None and isinstance(cp, InMemorySaver), \"A checkpointer instance of InMemorySaver should be created\"\n",
    "    assert 'agent' in globals(), \"agent should be defined\"\n",
    "    # If agent exposes a checkpointer attribute, ensure it's InMemorySaver\n",
    "    if hasattr(agent, 'checkpointer'):\n",
    "        assert isinstance(agent.checkpointer, InMemorySaver), \"agent.checkpointer should be an instance of InMemorySaver\"\n",
    "    print(\"Memory agent tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"Memory agent tests failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc59c2e",
   "metadata": {},
   "source": [
    "### Exercise 6.2 – Create a Memory‑Enabled Chat Loop\n",
    "\n",
    "Write a chat loop similar to Part 5, but supply a `config` dictionary to `agent.stream()`. In the config, there are two important parameters, including `thread_id` and `recursion_limit`.\n",
    "\n",
    "<img src=\"images/short_term_mem.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create config for memory\n",
    "config = {\n",
    "    'configurable': {\n",
    "        '...': ...,        # Specify thread id\n",
    "    },\n",
    "    'recursion_limit': ...      # Specify recursion limit\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa885ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 6.2\n",
    "try:\n",
    "    assert isinstance(config, dict), \"config should be a dictionary\"\n",
    "    assert 'configurable' in config, \"config should contain 'configurable' key as first level key\"\n",
    "    assert 'recursion_limit' in config, \"config should contain 'recursion_limit' key as first level key\"\n",
    "    assert isinstance(config['recursion_limit'], int) and config['recursion_limit'] > 0, \"recursion_limit should be a positive integer\"\n",
    "    assert isinstance(config['configurable'], dict), \"config['configurable'] should be a dictionary\"\n",
    "    assert 'thread_id' in config['configurable'], \"config['configurable'] should contain 'thread_id'\"\n",
    "    assert isinstance(config['configurable']['thread_id'], str) and config['configurable']['thread_id'], \"thread_id should be a non-empty string\"\n",
    "    print(\"Config creation tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"Config creation tests failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af68cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome to the LangGraph ReAct demo with memory! Ask me a question.')\n",
    "print('I can perform simple math, look up drug information, and search PubMed via LitSense.')\n",
    "print('====================================================================')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Get input prompt from user\n",
    "        user_input = input('User: ')\n",
    "    except EOFError:\n",
    "        break\n",
    "    \n",
    "    # If input contains one of three keywords: quit, exit, and q; exit the streaming process.\n",
    "    if not user_input or user_input.lower() in {'quit', 'exit', 'q'}:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    # Initialize graph state with user's input\n",
    "    state = {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': user_input}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Print the user's message first\n",
    "    print(f\"\"\"================================== User's Message ==================================\n",
    "{user_input}\n",
    "    \"\"\")\n",
    "    \n",
    "    # TODO: Supply config for the agent stream process\n",
    "    for event in agent.stream(state, config=...):\n",
    "        for value in event.values():\n",
    "            # The last message in the state is the AI response\n",
    "            msg = value[\"messages\"][-1]\n",
    "            # Use the built-in pretty_print method for better formatting\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037557d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7 – Prebuilt Agents\n",
    "\n",
    "LangGraph provides prebuilt agents that implement common architectures such as the ReAct pattern. These agents are quick to set up and let you focus on your tools and prompts rather than on graph wiring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a0d1b",
   "metadata": {},
   "source": [
    "### Exercise 7.1 – Create a Prebuilt Agent\n",
    "\n",
    "Use `create_react_agent` to instantiate a prebuilt ReAct agent. Provide your LLM, tools list, and a custom system prompt that instructs the agent how to behave.\n",
    "\n",
    "#### References: [LangGraph Prebuilt Tutorial](https://langchain-ai.github.io/langgraph/agents/agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config for memory\n",
    "config = {\n",
    "    'configurable': {\n",
    "        '...': ...,\n",
    "    },\n",
    "    'recursion_limit': ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078cdb6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "autotest",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 6.2 – Create a Memory‑Enabled Chat Loop Config\n",
    "try:\n",
    "    assert isinstance(config, dict), \"config should be a dictionary\"\n",
    "    assert 'configurable' in config, \"config should contain 'configurable' key as first level key\"\n",
    "    assert 'recursion_limit' in config, \"config should contain 'recursion_limit' key as first level key\"\n",
    "    assert isinstance(config['recursion_limit'], int) and config['recursion_limit'] > 0, \"recursion_limit should be a positive integer\"\n",
    "    assert isinstance(config['configurable'], dict), \"config['configurable'] should be a dictionary\"\n",
    "    assert 'thread_id' in config['configurable'], \"config['configurable'] should contain 'thread_id'\"\n",
    "    assert isinstance(config['configurable']['thread_id'], str) and config['configurable']['thread_id'], \"thread_id should be a non-empty string\"\n",
    "    print(\"Config creation tests passed!\")\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"Config creation tests failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = TOOLS,\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\",\n",
    "    checkpointer = checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33bdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome to the LangGraph ReAct demo with memory! Ask me a question.')\n",
    "print('I can perform simple math, look up drug information, and search PubMed via LitSense.')\n",
    "print('====================================================================')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Get input prompt from user\n",
    "        user_input = input('User: ')\n",
    "    except EOFError:\n",
    "        break\n",
    "    \n",
    "    # If input contains one of three keywords: quit, exit, and q; exit the streaming process.\n",
    "    if not user_input or user_input.lower() in {'quit', 'exit', 'q'}:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    # Initialize graph state with user's input\n",
    "    state = {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': user_input}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Print the user's message first\n",
    "    print(f\"\"\"================================== User's Message ==================================\n",
    "{user_input}\n",
    "    \"\"\")\n",
    "    \n",
    "    # Supply config for the agent stream process\n",
    "    for event in agent.stream(state, config=config):\n",
    "        for value in event.values():\n",
    "            # The last message in the state is the AI response\n",
    "            msg = value[\"messages\"][-1]\n",
    "            # Use the built-in pretty_print method for better formatting\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb6f7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8 – Extension Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb804636",
   "metadata": {},
   "source": [
    "### Exercise 8.1 – Create a system prompt using a prompt template\n",
    "\n",
    "In LangGraph, you can provide a **system** or **instruction** message that sets the behaviour of the assistant before any user input is processed. LangGraph exposes this functionality via its `prompts` module. There you will find a few classes: `PromptTemplate` for formatting a single string, `ChatPromptTemplate` for building multi-message prompts, and `MessagesPlaceholder` for inserting a slot where conversation history will later be filled.\n",
    "\n",
    "In this exercise, you will define a `ChatPromptTemplate` that begins with a system instruction. The system message should describe the assistant’s role (for example, instructing it to behave like a drug discovery researcher) and will be prepended to the user’s request before being passed to the agent.\n",
    "\n",
    "#### API References: [Prompt Template](https://python.langchain.com/docs/concepts/prompt_templates/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#TODO: Implement ChatPromptTemplate here\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"...\", \"...\"),\n",
    "    (\"user\", \"{request}\")\n",
    "])\n",
    "\n",
    "#TODO: Invoke the prompt_template to construct prompt_values, which are prompts that will be sent to the system\n",
    "prompt_values = prompt_template.invoke({'...':'What is the mechanism of action of remdesivir and what bioactivity data is available for this compound?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10f785",
   "metadata": {},
   "source": [
    "`prompt_values` is a dictionary, which can be invoke directly to the agent. Try out by simple invoke the agent with the `prompt_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = agent.invoke(prompt_values, config=config)\n",
    "for msg in msgs['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c292b84",
   "metadata": {},
   "source": [
    "### Exercise 8.2 – Integrate the system prompt with a streaming loop\n",
    "\n",
    "Building on the previous exercise, implement a multi-turn chat loop. Use a `while` loop to repeatedly accept user input, stream the agent’s response, and append both user and assistant messages to the conversation state.\n",
    "\n",
    "To include your system instruction in every turn, apply the `ChatPromptTemplate` from exercise 8.1 when constructing the input for the agent. \n",
    "\n",
    "When using the streaming API you must supply a `state` dictionary that includes a `'messages'` key. The value of this key should be a list of message dictionaries (each with `role` and `content` fields) representing the conversation history. \n",
    "\n",
    "As you loop, update this list to maintain the context across turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"example_conversation\",\n",
    "        \"recursion_limit\": 25,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert drug discovery researcher. Use your available tools to answer the user's question as accurately as possible. Never fabricate or invent data.\"),\n",
    "    (\"human\", \"{request}\"),\n",
    "])\n",
    "\n",
    "print(\"Welcome to the LangGraph ReAct demo with memory! Ask me a question.\")\n",
    "print(\"I can perform simple math, look up drug information, and search PubMed via LitSense.\")\n",
    "print(\"====================================================================\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "    if not user_input or user_input.lower() in {\"quit\", \"exit\", \"q\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    #TODO: Invoke prompt_template to construct prompt_values, then initilize state with prompt_values\n",
    "    prompt_values = prompt_template.invoke({'...': ...})\n",
    "    state = {\"messages\": prompt_values.messages}\n",
    "\n",
    "    # Print the user's message first\n",
    "    print(f\"\"\"================================== User's Message ==================================\n",
    "{user_input}\n",
    "    \"\"\")\n",
    "    \n",
    "    # Stream agent events\n",
    "    for event in agent.stream(state, config=config):\n",
    "        for value in event.values():\n",
    "            msg = value[\"messages\"][-1]\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50268e6c",
   "metadata": {},
   "source": [
    "### Exercise 9.1 - Structure Output Parser\n",
    "\n",
    "Structured output parsers let you control the format of the language model’s responses. Instead of returning free‑form text, the model follows a schema (such as a Pydantic model) so that other components can reliably consume its output.\n",
    "\n",
    "- **Why?** Downstream software often expects data in a specific JSON schema (e.g. key–value pairs).\n",
    "- **How?** Define a Pydantic `BaseModel` to describe the fields you need, then use `with_structured_output(...)` to attach this schema to your LLM.\n",
    "\n",
    "You can read more in the [LangGraph structured output guide](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/#define-model-tools-and-graph-state).\n",
    "\n",
    "The diagram below shows the high‑level structure of the system we’re about to build. One LLM is responsible for deciding when to call tools, and a second LLM is tasked with formatting the final response according to your schema.\n",
    "\n",
    "<img src=\"images/react_structured_output.png\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86cab8",
   "metadata": {},
   "source": [
    "First, we'll set up two language models:\n",
    "\n",
    "1. **Tool‑calling LLM**: This model can invoke the tools you defined earlier (calculator, literature search, etc.).\n",
    "2. **Structured output LLM**: This model will use a Pydantic schema to return the final answer as JSON with fields for drug names, justifications, and sources.\n",
    "\n",
    "When we later ask a question such as *\"Use LitSearch literature, give me two antiviral drugs that are potentially to treat COVID‑19\"*, the agent will search PubMed via LitSense, find candidate antivirals, and then format its answer using this schema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556caaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: create the tool-calling LLM\n",
    "llm = ChatOpenAI(model='gpt-5', temperature=0)\n",
    "llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "# Step 2: define a Pydantic schema describing the structured output we want\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DrugsInfo(BaseModel):\n",
    "    drugs: str = Field(description='a list of drug names')\n",
    "    justifications: str = Field(description='a list of justification for each drugs')\n",
    "    sources: str = Field(description='a list of citation for each drugs')\n",
    "\n",
    "# Step 3: create the structured output LLM\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "llm_with_structured_outputs = llm.with_structured_output(DrugsInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f21260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import Dict, List\n",
    "\n",
    "# Define the chatbot node: this function invokes the tool‑calling LLM and appends the AI message to state\n",
    "def chatbot(state: ChatState) -> Dict[str, List]:\n",
    "    \"\"\"The main chatbot node. It invokes the LLM with the current messages.\"\"\"\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "# Define the respond node: this function uses the structured‑output LLM to format the final answer\n",
    "def respond(state: ChatState):\n",
    "    # Extract only the content of each message for the structured LLM\n",
    "    response = llm_with_structured_outputs.invoke(\n",
    "        [HumanMessage(content=state[\"messages\"][i].content) for i in range(len(state[\"messages\"]))]\n",
    "    )\n",
    "    # Wrap the structured JSON as an AIMessage and return it\n",
    "    return {\"messages\": [AIMessage(content=response.model_dump_json())]}\n",
    "\n",
    "# TODO: efine a  routing function to decide whether to keep calling tools or format a final response\n",
    "def route_tools(state: ChatState):\n",
    "    ...\n",
    "    if ...:\n",
    "        return ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695833ad",
   "metadata": {},
   "source": [
    "<img src=\"images/graph_create_1.png\" width=\"800\">\n",
    "\n",
    "<img src=\"images/graph_create_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "# Build the state graph\n",
    "graph_builder = StateGraph(ChatState)\n",
    "\n",
    "# TODO: Add the nodes: chatbot, respond, and tools\n",
    "graph_builder.add_node(...)\n",
    "graph_builder.add_node(...)\n",
    "graph_builder.add_node(...)\n",
    "\n",
    "# TODO: Add the edges\n",
    "graph_builder.add_edge(...) # from START to chatbot\n",
    "graph_builder.add_conditional_edges(...) # from chatbot to respond or tools\n",
    "graph_builder.add_edge(...) # from tools to chatbot\n",
    "graph_builder.add_edge(...) # from respond to END\n",
    "\n",
    "# Compile the workflow into an executable agent\n",
    "agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print('Graph visualization not available in this environment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the agent a question and pretty‑print the structured response\n",
    "answer = agent.invoke({'messages': 'Use LitSearch literatures, give me 2 antiviral drugs that are potential to treat COVID-19'})\n",
    "answer['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd59a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Nodes** are functions that operate on state.\n",
    "- **Edges** define the flow between nodes.\n",
    "- **State** carries data through the agent. Use reducer functions such as `add_messages` to control how the state is updated.\n",
    "- **Tools** extend agent capabilities and are annotated with `@tool`.\n",
    "- **Memory** allows agents to maintain context across invocations.\n",
    "- **Prebuilt agents** provide quick solutions for common patterns but offer less control than a custom graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa566d4f",
   "metadata": {},
   "source": [
    "---\n",
    "## Resources\n",
    "\n",
    "- **LangChain Documentation** – https://docs.langchain.com/oss/python/langchain/overview\n",
    "- **LangGraph Documentation** – https://docs.langchain.com/oss/python/langgraph/overview\n",
    "- **ChEMBL Web Services** – https://chembl.gitbook.io/chembl-interface-documentation/web-services\n",
    "- **OpenAI API** – https://platform.openai.com/docs/\n",
    "\n",
    "These references can help you explore LangGraph and related libraries beyond the scope of this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5952c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**🎉 Congratulations! You've built your first AI agent with LangGraph!**\n",
    "\n",
    "Feel free to modify and extend your agent. You can experiment with new tools, different LLMs, and additional nodes to create even more capable and personalised agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
